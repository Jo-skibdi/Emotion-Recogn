Project aims to detect and classify human emotions from facial expressions in real-time or static images. Using machine learning and deep learning techniques, the system processes facial data, extracts features, and predicts emotions such as happiness, sadness, anger, surprise, etc. The project involves face detection, feature extraction (e.g., landmarks or embeddings), and emotion classification. Real-time applications include using OpenCV for video capture and integrating trained models for live emotion detection. The system achieved around 70% accuracy in this case, demonstrating its potential for applications in sentiment analysis, human-computer interaction, or mental health monitoring.
